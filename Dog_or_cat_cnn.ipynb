{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Dog_or_cat_cnn.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wNe7QKBQJfs-"
      },
      "outputs": [],
      "source": [
        "# importing required libraries\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense\n",
        "import urllib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# mounting drive to access dataset from drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aQRs-kKvS4Uc",
        "outputId": "d5627960-d844-43b0-d99c-d07b24dbcc37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Path ='drive/My Drive/Colab_Notebooks/dataset'"
      ],
      "metadata": {
        "id": "uL6EfwPrTJ62"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#initialize cnn\n",
        "classifier = Sequential()\n",
        "classifier.add(Conv2D(32,(3,3),input_shape=(64,64,3),activation = 'relu'))\n",
        "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
        "#second convolution layer\n",
        "classifier.add(Conv2D(32,(3,3),activation = 'relu'))\n",
        "classifier.add(MaxPooling2D(pool_size=(2,2)))"
      ],
      "metadata": {
        "id": "w2Lva6ePXMgH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#flattening\n",
        "classifier.add(Flatten())\n",
        "#full connection\n",
        "classifier.add(Dense(units=128,activation='relu'))\n",
        "classifier.add(Dense(units=1,activation='sigmoid'))\n",
        "#compiling cnn\n",
        "classifier.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "sExSfw2bXdGD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#fitting cnn to images\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(rescale=1./255,shear_range=0.2,zoom_range=0.2,horizontal_flip=True)\n",
        "#add directory to the location of dataset\n",
        "training_set = train_datagen.flow_from_directory('/content/drive/My Drive/Colab_Notebooks/dataset/training_set',target_size=(64,64),batch_size=32,class_mode='binary')\n",
        "test_datagen=ImageDataGenerator(rescale=1./255)\n",
        "test_set= train_datagen.flow_from_directory('/content/drive/My Drive/Colab_Notebooks/dataset/test_set',target_size=(64,64),batch_size=32,class_mode='binary')"
      ],
      "metadata": {
        "id": "MJBHuRP3vFLE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "394bec15-f208-446d-d2eb-b686c5d9e879"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 6937 images belonging to 2 classes.\n",
            "Found 0 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#training model\n",
        "classifier.fit(training_set,steps_per_epoch=6000,epochs=25,validation_data=test_set,validation_steps=1000)\n"
      ],
      "metadata": {
        "id": "COBu4n7J02ph",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68145d02-8118-4761-ba32-13642a155ac5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            " 217/6000 [>.............................] - ETA: 13:48:45 - loss: 0.6396 - accuracy: 0.6340WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 150000 batches). You may need to use the repeat() function when building your dataset.\n",
            "6000/6000 [==============================] - 1903s 310ms/step - loss: 0.6396 - accuracy: 0.6340\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2f7322e150>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#making new predictions\n",
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "testimage = image.load_img('/content/drive/My Drive/Colab_Notebooks/dataset/single_test/cat_or_dog_2.jpg',target_size=(64,64))\n",
        "testimage= image.img_to_array(testimage)\n",
        "testimage=np.expand_dims(testimage,axis=0)\n",
        "result = classifier.predict(testimage)\n",
        "training_set.class_indices\n",
        "if result[0][0]==1:\n",
        "  prediction = 'dog'\n",
        "else:\n",
        "  prediction = 'cat'\n",
        "print(prediction)"
      ],
      "metadata": {
        "id": "cO0KRJko7ZeZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1a06cbc-fafb-4144-edce-baab4709115c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cat\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PATH= './entire_model'\n",
        "net = classifier\n",
        "net.save(PATH)\n",
        "net = keras.models.load_model(PATH)\n",
        "print(net)"
      ],
      "metadata": {
        "id": "42H6ZhyMHClg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ecddd3f-1038-454c-a778-bb23e731d45e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: ./entire_model/assets\n",
            "<keras.engine.sequential.Sequential object at 0x7f2f80e1b990>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "BJxTQb5ZEW7k"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}